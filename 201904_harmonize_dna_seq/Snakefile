import csv
from pathlib import Path
from textwrap import dedent

# Path to the unharmonized cases
CASE_LIST_PTH = '../201904_locate_adhoc_data/tracked_results/unharmonized_cases.list'
# Path to the sequencing file mapping from Matt's catalog
MGI_MAP_PTH = '../matt_catalog/MGI.BamMap.dat'
GDC_REF_FA_PTH = '/gscmnt/gc2521/dinglab/mwyczalk/somatic-wrapper-data/image.data/A_Reference/GRCh38.d1.vd1.fa'
GDC_BWA_INDEX_PREFIX = GDC_REF_FA_PTH
EMAIL = 'liang-bo.wang@wustl.edu'

# Read the list of all the unharmonized cases
unharmonized_cases = set(open(CASE_LIST_PTH).read().splitlines())

# Build the sample (case, sample_type) BAM map on MGI {{{
# Data structure of the map
# (case, sample_type) -> bam_pth
wxs_bam_map = {}
wgs_bam_map = {}
with open(MGI_MAP_PTH) as f:
    reader = csv.DictReader(f, dialect='excel-tab')
    for row in reader:
        case = row['case']

        # Keep only the unharmonized cases of interest
        if not (case in unharmonized_cases \
                and row['reference'] == 'hg19' \
                and row['data_format'] == 'BAM'):
            continue

        # Get the corresponding bam map
        if row['experimental_strategy'] == 'WGS':
            bam_map = wgs_bam_map
        elif row['experimental_strategy'] == 'WXS':
            bam_map = wxs_bam_map

        sample = (case, row['sample_type'])
        bam_pth = Path(row['data_path'])
        bam_map[sample] = bam_pth
# }}}

# At the moment we only test for the first 5 cases
all_wxs_samples = [f'{case}_{st}' for (case, st) in sorted(wxs_bam_map.keys())][:10]


rule link_all_unharmonized_bams:
    """Link all unharmonized WXS BAMs."""
    input: CASE_LIST_PTH, MGI_MAP_PTH
    output:
        wxs_bams=[f'external_data/unharmonized_wxs/{case}_{sample_type}.bam' \
                  for (case, sample_type) in wxs_bam_map],
        wxs_bais=[f'external_data/unharmonized_wxs/{case}_{sample_type}.bam.bai' \
                  for (case, sample_type) in wxs_bam_map]
    run:
        for seq_type, bam_map in [('wxs', wxs_bam_map)]:
            for (case, sample_type), bam_src_pth in bam_map.items():
                # Link BAM
                bam_dst_pth = Path(f'external_data/unharmonized_{seq_type}/{case}_{sample_type}.bam')
                bam_dst_pth.symlink_to(bam_src_pth)

                # Link BAI
                bai_src_pth = bam_src_pth.with_suffix('.bam.bai')
                bai_dst_pth = bam_dst_pth.with_suffix('.bam.bai')
                bai_dst_pth.symlink_to(bai_src_pth)


checkpoint bam_to_fastqs:
    """Export reads as FASTQs from an aligned BAM."""
    input: bam='external_data/unharmonized_{seq_type}/{sample}.bam'
    output: sample_folder=directory('processed_data/{seq_type}_fqs/{sample}')
    log: 'logs/bam_to_fastqs/{seq_type}/{sample}.log'
    shell:
        'mkdir {output.sample_folder}; '
        'bamtofastq '
        'filename={input.bam} inputformat=bam '
        'collate=1 '
        'exclude=QCFAIL,SECONDARY,SUPPLEMENTARY '
        'gz=1 level=5 '
        'tryoq=1 '
        'combs=1 '
        'T=$(mktemp --tmpdir tmp_bamtofastq.XXXXXXXXXXXXXXXX) '  # Write temporary files under $TMPDIR
        'outputdir={output.sample_folder} '
        'outputperreadgroup=1 '
        'outputperreadgroupsuffixF=_1.fq.gz '
        'outputperreadgroupsuffixF2=_2.fq.gz '
        'outputperreadgroupsuffixO=_o1.fq.gz '
        'outputperreadgroupsuffixO2=_o2.fq.gz '
        'outputperreadgroupsuffixS=_s.fq.gz '
        '2>{log} 1>&2'


rule all_wxs_fastqs:
    """Export all WXS BAMs as FASTQs."""
    input:
        all_wxs_fqs=expand('processed_data/wxs_fqs/{sample}', \
                           sample=all_wxs_samples, strand=['r1', 'r2'])


def get_readgroups_of_one_sample(wildcards):
    """Get the available read groups of a sample."""
    sample_folder = Path(checkpoints.bam_to_fastqs.get(**wildcards).output['sample_folder'])
    all_readgroups = set(p.name[:-len('_1.fq.gz')] for p in sample_folder.glob('*_1.fq.gz'))
    # ignore the `default` RG
    all_readgroups -= set(['default'])
    return sorted(all_readgroups)


rule bwa_align_one_readgroup_fastq:
    """BWA MEM alignemnt of one readgroup FASTQs."""
    output: bam='processed_data/{seq_type}_readgroup_bam/{sample}/{rg}.bam'
    input:
        r1_fq='processed_data/{seq_type}_fqs/{sample}/{rg}_1.fq.gz',
        r2_fq='processed_data/{seq_type}_fqs/{sample}/{rg}_2.fq.gz'
    threads: 8
    resources:
        mem_mb=16000
    shell:
        dedent("""
        bwa mem \
            -t {threads} -T 0 \
            -R '@RG\\tID:{wildcards.rg}\\tSM:{wildcards.sample}' \
            {GDC_BWA_INDEX_PREFIX} {input.r1_fq} {input.r2_fq} \
        | samtools view -Shb -o {output.bam} -
        """)

rule picard_sort_one_readgroup_bam:
    """Picard sort one readgroup BAM."""
    output: bam='processed_data/{seq_type}_readgroup_bam/{sample}/{rg}.sorted.bam'
    input: bam=rules.bwa_align_one_readgroup_fastq.output['bam']
    threads: 2
    resources:
        mem_mb=8000
    log: 'logs/picard_sort_rg_bam/{seq_type}/{sample}/{rg}.log'
    shell:
        "picard -Xmx{resources.mem_mb}m SortSam "
        "CREATE_INDEX=true "
        "I={input.bam} "
        "O={output.bam} "
        "SORT_ORDER=coordinate "
        "VALIDATION_STRINGENCY=STRICT "
        "TMP_DIR=$(mktemp -d --tmpdir tmp_picard.XXXXXXXXXXXXXXXX) "
        "2>{log} 1>&2"


def get_readgroup_bams_of_one_sample(wildcards):
    all_readgroups = get_readgroups_of_one_sample(wildcards)
    return [
        f'processed_data/{wildcards.seq_type}_readgroup_bam/'
        f'{wildcards.sample}/{rg}.sorted.bam'
        for rg in all_readgroups
    ]


rule picard_merge_readgroup_bams_of_one_sample:
    """Merge all readgroup BAMs of one sample by Picard."""
    output:
        merged_bam='processed_data/{seq_type}_merged_bam/{sample}.bam',
        merged_bai='processed_data/{seq_type}_merged_bam/{sample}.bam.bai'
    input: readgroup_bams=get_readgroup_bams_of_one_sample
    params:
        input_bams_args=lambda wildcards, input: \
            [f'I={pth}' for pth in input['readgroup_bams']],
        bsub_extra=f'-N -u {EMAIL}'
    threads: 2
    resources:
        mem_mb=16000
    log: 'logs/picard_merge_bams/{seq_type}/{sample}.log'
    shell:
        "picard -Xmx{resources.mem_mb}m MergeSamFiles "
        "ASSUME_SORTED=false "
        "CREATE_INDEX=true "
        "MERGE_SEQUENCE_DICTIONARIES=false "
        "{params.input_bams_args} "
        "O={output.merged_bam} "
        "USE_THREADING=true "
        "SORT_ORDER=coordinate "
        "VALIDATION_STRINGENCY=STRICT "
        "TMP_DIR=$(mktemp -d --tmpdir tmp_picard.XXXXXXXXXXXXXXXX) "
        "2>{log} 1>&2"


rule all_wxs_picard_merged_bams:
    """Merge all WXS samples by Picard."""
    input: bams=[f'processed_data/wxs_merged_bam/{sample}.bam' \
                 for sample in all_wxs_samples]
