import csv
from collections import namedtuple
from pathlib import Path

OMIC_UUID_MANIFEST = '../201811_locate_gdc_data/tracked_results/CPTAC3_GBM_GDC_omics_UUIDs.tsv'
KATMAI_MAP = '../201811_locate_gdc_data/matt_catelog/katmai.BamMap.dat'
ENSEMBL_VER = '90'

SAMPLES = set()
with open(OMIC_UUID_MANIFEST) as f:
    reader = csv.DictReader(f, dialect='excel-tab')
    SAMPLES = set(row['case'] for row in reader)

SALMON_INDEX = 'processed_data/tx_ref/ensembl_90_good_tsl_index'


# GTEx {{{
GTEX_brain_cortex_samples = [
    # 'GTEX-R55F-1326-SM-5S2V4', 'GTEX-R55F-1326-SM-2TF5F',
    'GTEX-RU72-3026-SM-5SI7Y', 'GTEX-Y8DK-0826-SM-4TT3T',
    'GTEX-Q2AG-2926-SM-2HMJ3', 'GTEX-NPJ7-2726-SM-2I3FT',
    'GTEX-QVJO-1426-SM-2S1QY', 'GTEX-UTHO-3026-SM-3GAFB',
    'GTEX-WVLH-3026-SM-3MJG9'
]

# Use ready gene-level GTEx TPMs
rule download_gtex_gene_tpm:
    """Download GTEx official release of gene-level TPM."""
    output: 'external_data/GTEx_v7_gene_tpm.gct.gz'
    params: url='https://storage.googleapis.com/gtex_analysis_v7/rna_seq_data/GTEx_Analysis_2016-01-15_v7_RNASeQCv1.1.8_gene_tpm.gct.gz'
    shell:
        'curl -L -o {output} {params.url}'


rule extract_related_gtex:
    input: rules.download_gtex_gene_tpm.output[0]
    output: 'processed_data/gtex_gene_tpm.selected_samples.tsv.gz'
    params: selected_samples=[*GTEX_brain_cortex_samples]
    script: 'scripts/extract_gtex.py'


# Load GTEx BAMs
# GTExBAM = namedtuple('GTExBAM', 'case srr_id')
# GTEX_BRAIN_CORTEX_SAMPLES = [
#     GTExBAM(*case) for case in [
#         # case        brain cortex SRR id
#         ["GTEX-R55F", "SRR1417912"],
#         ["GTEX-RU72", "SRR1475168"],
#         ["GTEX-Y8DK", "SRR1480059"],
#         ["GTEX-Q2AG", "SRR602927"],
#         ["GTEX-NPJ7", "SRR604026"],
#         # ["GTEX-R55F", "SRR615213"],
#         ["GTEX-QVJO", "SRR615838"],
#         ["GTEX-UTHO", "SRR656745"],
#         ["GTEX-WVLH", "SRR810877"],
#     ]
# ]
# all_gtex_brain_cortex_bams = expand('external_data/GTEx_RNA_bam/{case}.brain_cortex.bam', case=[s.case for s in GTEX_BRAIN_CORTEX_SAMPLES])
#
# rule copy_gtex_rnaseq_bams:
#     output: all_gtex_brain_cortex_bams
#     params:
#         mgi_bam_root='/gscmnt/gc2802/halllab/cchiang/projects/gtex/rna-seq/4101/bam'
#     run:
#         for sample in GTEX_BRAIN_CORTEX_SAMPLES:
#             shell(
#                 "rsync -a --info=progress2 --partial --bwlimit=25000 "
#                 "vw5.gsc.wustl.edu:{params.mgi_bam_root}/{sample.srr_id}.bam "
#                 "external_data/GTEx_RNA_bam/{sample.case}.brain_cortex.bam"
#             )
#             shell(
#                 "rsync -a --info=progress2 "
#                 "vw5.gsc.wustl.edu:{params.mgi_bam_root}/{sample.srr_id}.bam.bai "
#                 "external_data/GTEx_RNA_bam/{sample.case}.brain_cortex.bam.bai"
#             )

# # Note that the GTEx BAM is half the size of CPTAC BAMs
# rule gtex_bam_to_fq:
#     input: 'external_data/GTEx_RNA_bam/{case}.brain_cortex.bam'
#     output:
#         r1='processed_data/GTEx_RNA_fq/{case}.R1.fastq.gz',
#         r2='processed_data/GTEx_RNA_fq/{case}.R2.fastq.gz'
#     shell:
#         'samtools fastq -1 {output.r1} -2 {output.r2} -c 9 -0 /dev/null -s /dev/null -n -F 0x900 {input}'



# }}}


rule link_gdc_rna_fastq:
    """Link the RNA-seq fastqs locally."""
    input: manifest=OMIC_UUID_MANIFEST,
           local_map=KATMAI_MAP
    output: expand('external_data/GDC_RNA_fq/{sample}.{read}.fastq.gz', sample=SAMPLES, read=['R1', 'R2'])
    run:
        # Create a UUID to local file path map
        uuid_to_local_file_pth = {}
        with open(input['local_map']) as f:
            reader = csv.DictReader(f, dialect='excel-tab')
            for row in reader:
                # Keep only RNA-seq UUIDs
                if row['experimental_strategy'] == 'RNA-Seq':
                    uuid_to_local_file_pth[row['UUID']] = Path(row['data_path'])

        # Link the FASTQs
        with open(input['manifest']) as f:
            reader = csv.DictReader(f, dialect='excel-tab')
            for row in reader:
                sample = row['case']
                r1_uuid = row['rna_tumor_R1_fastq']
                r2_uuid = row['rna_tumor_R2_fastq']

                r1_src_pth = uuid_to_local_file_pth[r1_uuid]
                r2_src_pth = uuid_to_local_file_pth[r2_uuid]
                r1_dst_pth = Path(f'external_data/GDC_RNA_fq/{sample}.R1.fastq.gz')
                r2_dst_pth = Path(f'external_data/GDC_RNA_fq/{sample}.R2.fastq.gz')
                r1_dst_pth.symlink_to(r1_src_pth)
                r2_dst_pth.symlink_to(r2_src_pth)


rule download_tx_ref:
    """Download transcript related reference files."""
    output:
        gtf='external_data/genome_ref/Homo_sapiens.GRCh38.90.gtf.gz',
        cdna='external_data/genome_ref/Homo_sapiens.GRCh38.cdna.all.fa.gz'
    params:
        ensembl_gtf_url='ftp://ftp.ensembl.org/pub/release-90/gtf/homo_sapiens/Homo_sapiens.GRCh38.90.gtf.gz',
        ensembl_cdna_url='ftp://ftp.ensembl.org/pub/release-90/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all.fa.gz'
    shell:
        '''
        curl {params.ensembl_gtf_url} -o {output.gtf}
        curl {params.ensembl_cdna_url} -o {output.cdna}
        '''

# Build Salmon index of TSL1 or TSLNA {{{
rule create_gffutils_db:
    """Create a GTF database for fast query."""
    input: rules.download_tx_ref.output['gtf']
    output: 'processed_data/ensembl_tx_gtf_90.db'
    script: 'scripts/create_gffutils_db.py'


rule export_tx_good_tsl:
    """Export transcript IDs of good TSL and protein coding."""
    input: rules.create_gffutils_db.output[0]
    output: 'processed_data/ensembl_tx_ids_good_tsl.list'
    script: 'scripts/export_high_conf_protein_coding_transcripts.py'


rule subset_cdna_fa:
    """Subset the cDNA fasta file."""
    input:
        cdna_fa=rules.download_tx_ref.output['cdna'],
        tx_list=rules.export_tx_good_tsl.output[0]
    output: 'processed_data/tx_ref/ensembl_90.cdna.good_tsl.fa.gz'
    script: 'scripts/subset_cdna.py'


rule build_salmon_index:
    """Build Salmon transcript index."""
    input: rules.subset_cdna_fa.output[0]
    output: 'processed_data/tx_ref/ensembl_90_good_tsl_index/hash.bin'
    params: salmon_ix=SALMON_INDEX
    threads: 2
    shell:
        'salmon index --threads {threads} -t {input} -i {params.salmon_ix}'
# }}}

rule quant_one_sample:
    """Gene quantification on one sample using Salmon."""
    input:
        r1_fq='external_data/GDC_RNA_fq/{sample}.R1.fastq.gz',
        r2_fq='external_data/GDC_RNA_fq/{sample}.R2.fastq.gz'
    output: 'processed_data/quants/{sample}/quant.sf'
    params:
        salmon_ix=SALMON_INDEX,
        out_folder='processed_data/quants/{sample}'
    threads: 4
    log: 'logs/salmon_quants/{sample}.log'
    shell:
        'salmon quant -i {params.salmon_ix} -l A --gcBias '
        '-1 {input.r1_fq} -2 {input.r2_fq} '
        '-p {threads} -o {params.out_folder} '
        '2> {log}'


rule quant_all_samples:
    input: expand('processed_data/quants/{sample}/quant.sf', sample=SAMPLES)


# Use the same set of samples for experiments
SAMPLES_FOR_EXP = ['C3L-00016', 'C3L-01839']

# Experiment: Salmon using full transcript reference set {{{
rule quant_one_sample_full_tx_ref:
    """Gene quantification on one sample using Salmon and using full Ensembl transcript set."""
    input:
        r1_fq='external_data/GDC_RNA_fq/{sample}.R1.fastq.gz',
        r2_fq='external_data/GDC_RNA_fq/{sample}.R2.fastq.gz'
    output: 'processed_data/experiments/full_tx_ref_quants/{sample}/quant.sf'
    params:
        salmon_ix='processed_data/tx_ref/ensembl_90_full_index',
        out_folder='processed_data/experiments/full_tx_ref_quants/{sample}'
    threads: 4
    shell:
        'salmon quant -i {params.salmon_ix} -l A --gcBias '
        '-1 {input.r1_fq} -2 {input.r2_fq} '
        '-p {threads} -o {params.out_folder} '

rule experiment_full_tx:
    input: expand('processed_data/experiments/full_tx_ref_quants/{sample}/quant.sf', sample=SAMPLES_FOR_EXP)
# }}}


# Experiment: STAR two pass alignment {{{
GENOME_FA = '/diskmnt/Datasets/Reference/GRCh38.d1.vd1/GRCh38.d1.vd1.fa'
STAR_INDEX_FOLDER = '/diskmnt/Datasets/Reference/GDC/star_genome_d1_vd1_gtfv22.rebuild'
STAR_GTF = '/diskmnt/Datasets/Reference/GDC/gencode.v22.annotation.gtf'


rule star_align_pass1:
    """STAR genome alignemnt pass 1 of one sample."""
    input:
        r1_fq='external_data/GDC_RNA_fq/{sample}.R1.fastq.gz',
        r2_fq='external_data/GDC_RNA_fq/{sample}.R2.fastq.gz'
    output:
        sj='processed_data/experiments/star/{sample}/pass1/SJ.out.tab'
    params:
        star_ix=STAR_INDEX_FOLDER,
        star_gtf=STAR_GTF,
        out_folder='processed_data/experiments/star/{sample}/pass1/'
    log: 'logs/star_pass1/{sample}.log'
    threads: 4
    shell:
        'STAR '
        '--genomeDir {params.star_ix} '
        '--readFilesIn {input.r1_fq} {input.r2_fq} '
        '--readFilesCommand zcat '
        '--runThreadN {threads} '
        '--outFileNamePrefix {params.out_folder} '
        '--outFilterMultimapScoreRange 1 '
        '--outFilterMultimapNmax 20 '
        '--outFilterMismatchNmax 10 '
        '--alignIntronMax 500000 '
        '--alignMatesGapMax 1000000 '
        '--sjdbScore 2 '
        '--alignSJDBoverhangMin 1 '
        '--genomeLoad NoSharedMemory '
        '--outFilterMatchNminOverLread 0.33 '
        '--outFilterScoreMinOverLread 0.33 '
        '--sjdbOverhang 100 '
        '--outSAMstrandField intronMotif '
        '--outSAMtype None '
        '--outSAMmode None '
        '> {log}'


rule star_align_pass2:
    """STAR genome alignemnt pass 2 of one sample."""
    input:
        r1_fq='external_data/GDC_RNA_fq/{sample}.R1.fastq.gz',
        r2_fq='external_data/GDC_RNA_fq/{sample}.R2.fastq.gz',
        all_pass1_sj_tabs=expand('processed_data/experiments/star/{sample}/pass1/SJ.out.tab', sample=SAMPLES_FOR_EXP)
    output:
        bam='processed_data/experiments/star/{sample}/pass2/Aligned.sortedByCoord.out.bam'
    params:
        star_ix=STAR_INDEX_FOLDER,
        star_gtf=STAR_GTF,
        out_folder='processed_data/experiments/star/{sample}/pass2/'
    log: 'logs/star_pass2/{sample}.log'
    threads: 4
    shell:
        # Run the same command as pass1, but passing the split junction tabs of all samples
        'STAR '
        '--genomeDir {params.star_ix} '
        '--readFilesIn {input.r1_fq} {input.r2_fq} '
        '--readFilesCommand zcat '
        '--runThreadN {threads} '
        '--outFileNamePrefix {params.out_folder} '
        '--outFilterMultimapScoreRange 1 '
        '--outFilterMultimapNmax 20 '
        '--outFilterMismatchNmax 10 '
        '--alignIntronMax 500000 '
        '--alignMatesGapMax 1000000 '
        '--sjdbScore 2 '
        '--alignSJDBoverhangMin 1 '
        '--genomeLoad NoSharedMemory '
        '--outFilterMatchNminOverLread 0.33 '
        '--outFilterScoreMinOverLread 0.33 '
        '--sjdbOverhang 100 '
        # Pass SJ tabs of all samples (main difference to PASS 1)
        '--sjdbFileChrStartEnd {input.all_pass1_sj_tabs} '
        '--limitBAMsortRAM 0 '
        '--outSAMstrandField intronMotif '
        '--outSAMattributes NH HI NM MD AS XS '
        '--outSAMunmapped Within '
        '--outSAMtype BAM SortedByCoordinate '
        # Add SAM version number (likely no effect on anything)
        # Ref: https://www.biostars.org/p/121135/#121138
        '--outSAMheaderHD @HD VN:1.4 '
        '> {log}'


rule subread_featurecounts:
    """Readcount by featureCounts (Subread)"""
    input:
        bam=expand('processed_data/experiments/star/{sample}/pass2/Aligned.sortedByCoord.out.bam', sample=SAMPLES_FOR_EXP)
    output:
        count_tsv='processed_data/experiments/star/all_samples_featurecounts.tsv'
    params:
        gtf=STAR_GTF
    log: 'logs/all_samples_featurecounts.log'
    threads: 4
    shell:
        'featureCounts '
        '-g gene_id '  # feature id (-i in htseq)
        '-t exon ' # feature type (-t in htseq)
        '-T {threads} '
        '-Q 10 ' # htseq set this minimal mapping quality by default
        '-a {params.gtf} '
        '-o {output.count_tsv} {input.bam} 2> {log}'


rule experiment_star:
    """Experiment using STAR alignment pipeline (adopted from GDC)"""
    input: rules.subread_featurecounts.output
# }}}

# vim:set foldmethod=marker:
