import csv
from collections import namedtuple
from textwrap import dedent
from pathlib import Path

# Path to the mapping of UUID to file location on katmai
BAM_MAP_PTH = '../matt_catalog/MGI.BamMap.dat'
ENSEMBL_VER = 96
GENCODE_VER = 30
SALMON_INDEX_FOLDER_FMT = 'processed_data/tx_ref/{annotation_src}_salmon_index'
ALL_ANNOTATION_SOURCES = ['gencode_basic', 'gencode_comp', 'ensembl']

# The difference between case and sample
CPTAC_CASE_LIST_PTH = '../201904_locate_adhoc_data/tracked_results/rna_tumor_cases_on_MGI.list'
GTEX_SAMPLES_LIST_PTH = '../201904_locate_adhoc_data/tracked_results/gtex_normal_samples.list'
GTEX_FASTQ_FOLDER = '/gscmnt/gc2541/cptac3_analysis/GTEx_RNA_fq'

# Build Salmon indices (GENCODE and Ensembl) {{{
rule download_ensembl_ref:
    """Download Ensembl transcript annotation files."""
    output:
        gtf=f'external_data/ensembl_ref/Homo_sapiens.GRCh38.{ENSEMBL_VER}.gtf.gz',
        cdna='external_data/ensembl_ref/Homo_sapiens.GRCh38.cdna_and_ncrna.fa.gz'
    params:
        gtf_url=f'ftp://ftp.ensembl.org/pub/release-{ENSEMBL_VER}/gtf/homo_sapiens/Homo_sapiens.GRCh38.{ENSEMBL_VER}.gtf.gz',
        cdna_url=f'ftp://ftp.ensembl.org/pub/release-{ENSEMBL_VER}/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all.fa.gz',
        ncrna_url=f'ftp://ftp.ensembl.org/pub/release-{ENSEMBL_VER}/fasta/homo_sapiens/ncrna/Homo_sapiens.GRCh38.ncrna.fa.gz'
    shell:
        # Note that Ensembl stores noncoding sequences in a separate FASTA file,
        # so we concatenate the two gzip'd FASTA files together.
        dedent('''
        curl {params.gtf_url} -o {output.gtf}
        curl {params.cdna_url} -o {output.cdna}
        curl {params.ncrna_url} -o- >> {output.cdna}
        ''')


rule extract_ensembl_tx_list:
    """Extract the list of Ensembl transcript IDs."""
    output: 'processed_data/tx_ref/ensembl_tx_ids.list'
    input: rules.download_ensembl_ref.output['gtf']
    shell:
        dedent(r"""
        gunzip -c {input} \
        | awk '{{if ($3 == "transcript") print}}' \
        | sed -r 's/.*transcript_id "(\w+)"; transcript_version "(\w+)";.*/\1.\2/' \
        > {output}
        """)


rule download_gencode_ref:
    """Download GENCODE basic transcript annotation files."""
    output:
        basic_gtf=f'external_data/gencode_ref/gencode.v{GENCODE_VER}.basic.annotation.gtf.gz',
        comp_gtf=f'external_data/gencode_ref/gencode.v{GENCODE_VER}.comp.annotation.gtf.gz',
        cdna=f'external_data/gencode_ref/gencode.v{GENCODE_VER}.transcripts.fa.gz'
    params:
        basic_gtf_url=f'ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_{GENCODE_VER}/gencode.v{GENCODE_VER}.basic.annotation.gtf.gz',
        comp_gtf_url=f'ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_{GENCODE_VER}/gencode.v{GENCODE_VER}.annotation.gtf.gz',
        cdna_url=f'ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_{GENCODE_VER}/gencode.v{GENCODE_VER}.transcripts.fa.gz'
    shell:
        dedent('''
        curl {params.basic_gtf_url} -o {output.basic_gtf}
        curl {params.comp_gtf_url} -o {output.comp_gtf}
        curl {params.cdna_url} -o {output.cdna}
        ''')


rule extract_gencode_tx_list:
    """Extract the list of GENCODE transcript IDs."""
    output: tx_list='processed_data/tx_ref/gencode_{lib}_tx_ids.list'
    input: gtf=f'external_data/gencode_ref/gencode.v{GENCODE_VER}.{{lib}}.annotation.gtf.gz'
    shell:
        dedent(r"""
        gunzip -c {input.gtf} \
        | awk '{{if ($3 == "transcript") print}}' \
        | sed -r 's/.*transcript_id "([.A-Z0-9_]+)";.*/\1/' \
        | grep --invert-match -e '_PAR_Y$' \
        > {output.tx_list}
        """)


def find_annotation_cdna(wildcards):
    if wildcards.annotation_src == 'ensembl':
        return {
            'tx_list': rules.extract_ensembl_tx_list.output[0],
            'cdna_fa': rules.download_ensembl_ref.output['cdna'],
        }
    elif wildcards.annotation_src == 'gencode_comp':
        return {
            'tx_list': 'processed_data/tx_ref/gencode_comp_tx_ids.list',
            'cdna_fa': rules.download_gencode_ref.output['cdna'],
        }
    elif wildcards.annotation_src == 'gencode_basic':
        return {
            'tx_list': 'processed_data/tx_ref/gencode_basic_tx_ids.list',
            'cdna_fa': rules.download_gencode_ref.output['cdna'],
        }
    else:
        raise ValueError(f'Unknown annotation source: {wildcards.annotation_src}')


rule subset_cdna_fasta:
    """Subset the cDNA FASTA to only include transcripts of interest."""
    output:
        out_fa='processed_data/tx_ref/{annotation_src}_selected_cdna.fa.gz',
        missing_tx_list='processed_data/tx_ref/{annotation_src}_missing_tx_ids.list'
    input: unpack(find_annotation_cdna)
    log: 'logs/tx_ref/{annotation_src}/subset_cdna.log'
    script: 'scripts/subset_cdna_fa.py'


rule build_salmon_index:
    """Build Salmon index."""
    output: 'processed_data/tx_ref/{annotation_src}_salmon_index/hash.bin'
    input: rules.subset_cdna_fasta.output['out_fa']
    params: salmon_ix_folder=SALMON_INDEX_FOLDER_FMT
    threads: 4
    log: 'logs/tx_ref/{annotation_src}/salmon_index.log'
    shell:
        'salmon index '
        '--threads {threads} '
        '-t {input} '
        '-i {params.salmon_ix_folder} '
        '-k 31 '  # kmer length
        '2> {log}'


rule build_all_salmon_indices:
    """Build Salmon indices of GENCODE and Ensembl."""
    input: expand(rules.build_salmon_index.output[0], annotation_src=ALL_ANNOTATION_SOURCES)
# }}}


# Collect all CPTAC samples
# Since only the tumor sample of each case has RNA-seq, we use case name here
CPTAC_SAMPLES = set(open(CPTAC_CASE_LIST_PTH).read().splitlines())

# Collect all GTEx samples
GTEX_SAMPLES = set(open(GTEX_SAMPLES_LIST_PTH).read().splitlines())


# Link CPTAC RNA-seq FASTQs
rule link_cptac_gdc_rna_fastqs:
    """Link the CPTAC RNA-seq fastqs locally."""
    input: local_map=BAM_MAP_PTH
    output: expand('external_data/CPTAC_RNA_fq/{sample}.{read}.fastq.gz', \
                   sample=CPTAC_SAMPLES, read=['R1', 'R2'])
    run:
        # Create a UUID to local file path map
        uuid_to_local_file_pth = {}
        with open(input['local_map']) as f:
            reader = csv.DictReader(f, dialect='excel-tab')
            for row in reader:
                if not (row['case'] in CPTAC_SAMPLES and
                        row['experimental_strategy'] == 'RNA-Seq' and
                        row['data_format'] == 'FASTQ'):
                    continue
                # only the tumor case is used, use case name as sample name
                sample = row['case']
                # get the RNA strand
                strand = row['# sample_name'].rsplit('.', 2)[-2]
                assert strand in ('R1', 'R2')
                src_pth = Path(row['data_path'])
                dst_pth = Path(f'external_data/CPTAC_RNA_fq/{sample}.{strand}.fastq.gz')
                dst_pth.symlink_to(src_pth)


def find_rna_fastq(wildcards):
    """Find the corresponding FASTQs of a sample."""
    sample = wildcards.sample
    if sample in CPTAC_SAMPLES:
        return {
            'r1_fq': f'external_data/CPTAC_RNA_fq/{sample}.R1.fastq.gz',
            'r2_fq': f'external_data/CPTAC_RNA_fq/{sample}.R2.fastq.gz',
        }
    elif sample in GTEX_SAMPLES:
        return {
            'r1_fq': f'{GTEX_FASTQ_FOLDER}/{sample}.R1.fastq.gz',
            'r2_fq': f'{GTEX_FASTQ_FOLDER}/{sample}.R2.fastq.gz',
        }
    else:
        raise ValueError(f'Sample {sample} is not part of CPTAC nor GTEx.')


rule salmon_quant_one_sample:
    """Gene quantification of one sample using Salmon."""
    output: 'processed_data/salmon_quants/{annotation_src}/{sample}/quant.sf'
    input:
        unpack(find_rna_fastq),
        salmon_ix=rules.build_salmon_index.output[0]
    params:
        salmon_ix_folder=SALMON_INDEX_FOLDER_FMT,
        out_folder='processed_data/salmon_quants/{annotation_src}/{sample}'
    threads: 4
    resources:
        mem_mb=8000
    log: 'logs/salmon_quants/{annotation_src}/{sample}.log'
    shell:
        'salmon quant '
        '-i {params.salmon_ix_folder} '  # Path to the Salmon index folder
        '-l A '  # Automatically detect library type
        '--gcBias '  # Correct for GC bias
        '--seqBias '  # Correct for radnom haxomer priming bias
        '--validateMappings '  # Confirm the quantification by actual alignment
        '--mimicBT2 '  # meta flag to enable Bowtie2 like behavior
        '--rangeFactorizationBins 4 '  # Fine tuning the transcript quantification
        '-1 {input.r1_fq} -2 {input.r2_fq} '
        '-p {threads} '
        '-o {params.out_folder} '
        '2> {log}'


rule salmon_quant_all_cptac_samples:
    """Gene quantification on all CPTAC samples using all annotation sources."""
    input: expand(rules.salmon_quant_one_sample.output[0], \
                  annotation_src=ALL_ANNOTATION_SOURCES, sample=CPTAC_SAMPLES)

rule salmon_quant_all_gtex_samples:
    """Gene quantification on all GTEX samples using all annotation sources."""
    input: expand(rules.salmon_quant_one_sample.output[0], \
                  annotation_src=ALL_ANNOTATION_SOURCES, sample=GTEX_SAMPLES)
